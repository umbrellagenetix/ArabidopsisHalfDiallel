setwd("~/Desktop/Archive_April2019/CSJ-Review/Revisions/")

library(reshape2)
library(linkcomm)
library(caret)
library(lme4)
library(ggplot2)

############
#### LOBLOLLY PINE DATA SET
##### Phenotypic Relationship Graph for Pitch Cancer Lesion Length
data<-read.table("FBRC-phenotypes.csv", header=T, sep=",", na.strings = "na")
data$Line<-as.factor(data$Line)
data$Family<-as.factor(data$Family)

dcast(data,P1~P2, value.var = "LOG.LL",mean, na.rm=TRUE)->data.ll
melt(data.ll, id.vars = "P1")->data.ll.1
data.ll.2<-na.omit(data.ll.1)
colnames(data.ll.2)<-c("P1","P2","logLL")

#there are nagative values in the blups add +1 to all values
data.ll.3<-data.ll.2
data.ll.3$logLL<-data.ll.3$logLL+1
#higher the weight - shorter the edge length, so
data.ll.3$logLL<-1/data.ll.3$logLL


getLinkCommunities(data.ll.3,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lcm
plot(lcm, type = "graph", layout = "spencer.circle")
plot(lcm, type = "graph", layout = layout.fruchterman.reingold)
plot(lcm, type = "graph", layout = layout.kamada.kawai)
## select layouts from https://rdrr.io/cran/linkcomm/man/plotLinkCommGraph.html

getLinkCommunities(data.ll.2,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lcm.1
plot(lcm.1, type = "graph", layout = "spencer.circle")
plot(lcm.1, type = "graph", layout = layout.fruchterman.reingold)

write.table(data.ll.3,"fbrc_ll_phenos_edgeList.csv",sep=",", row.names = FALSE)


### Genetic Relationship Graph for FBRC parents
## Need to create parental Genotypes from sequence and then create a K matrix
read.table("FBRC_kinship.txt", skip=3, header=F)->fbrc.k
kmat<-as.matrix(fbrc.k[,-1])
colnames(kmat)<-fbrc.k[,1]
rownames(kmat)<-fbrc.k[,1]
melt(kmat)->kmat.long
colnames(kmat.long)<-c("P1","P2","K")

## too crowded the graph - only include the edges that are greater then 0.25
kmat.long[which(kmat.long$K>0.25),]->kmr


getLinkCommunities(kmr,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lck
#getLinkCommunities(kmr.long,hcmethod="average", directed=FALSE, bipartite = FALSE)->lck
#lck <- newLinkCommsAt(lck, cutat = 0.81)
#plot(lck.1, type = "dend")

plot(lck, type = "graph", layout = "spencer.circle")
plot(lck, type = "graph", layout = layout.kamada.kawai)
plot(lck, type = "graph", layout = layout.fruchterman.reingold)

## much better displays the split network
write.table(kmr,"fbrc_K_edgeList.csv",sep=",", row.names = FALSE)

### Fraction of Transgressive Segregants??
### Can't do this with FBRC - don't have parent phenotypes.only genotypes
### Gogce's paper had SCA and GCA-can also be calculated from phenos

####### Arabidopsis Diallele Data Set ################
####### : https://doi.org/10.1073/pnas.1615268113 ####

## Phenotype File processing
setwd("/Users/eersoz/Desktop/Archive_April2019/CSJ-Review/Revisions/ArabidopsisDiallele/phenos")
fileList<-list.files(pattern="down")

phenoFile<-data.frame(
  FID=character(0L),
  IID=character(0L),
  value=numeric(0),
  Trait=character(0L)
)

for (i in (1:length(fileList))){
  a<-read.table(fileList[i], header=T, sep =" ")
  a$Trait<-colnames(a)[3]
  colnames(a)<-c("FID","IID","value","Trait")
  phenoFile<-rbind(phenoFile,a)
}

phenoFile$Trait<-as.factor(phenoFile$Trait)
dcast(phenoFile, FID~Trait, value.var = "value",sum)->phenoMat

write.table(phenoMat,"phenotype-matrix.csv",sep=",",row.names = FALSE)
## all data looks sufficiently normally distributed.
## Find the sample to family ID matches to anotate entries with cross and parents.
## That is Table S1 from DataDryad
setwd("../")
read.table("TableS1-Pedigree.csv", header=T, sep=",")->pedFile

dcast(pedFile, P1~P2, value.var = "CID")->pedMat
#write.table(pedMat,"pedigreeMatrix.csv",sep=",",row.names = FALSE)

# phenotypic similarity matrix
read.table("genoD+Phenos.csv", header=T, sep=",")->da1
da2<-da1[,c(3:4,6:22)]
dist(as.matrix(da2), method = "euclidean", diag = FALSE, upper = FALSE, p = 2)->dd2
as.matrix(dd2)->md2
colnames(md2)<-paste(da1$P1.P2)
rownames(md2)<-paste(da1$P1.P2)

heatmap(md2) #looks like 3 distinct communities
melt(md2)->dm # genetic Relationship matrix for the F1s

## phenotypicSimality Matrix is DM
## MPH is for mid parent heterosis
## Calculate Frequency of MPH+ and MPH- generated by each cross across across phenotypes.
## First extract out the phenotypes that have MPH tag

mphPhenos<-phenoMat[,which(grepl("MPH",colnames(phenoMat))==TRUE)]
mphPhenos$FID<-phenoMat$FID

regPhenos<-phenoMat[,which(grepl("MPH",colnames(phenoMat))==FALSE)]

## add the parent id'd to both
mph.1<-merge(pedFile,mphPhenos, by.x = "CID",by.y="FID")
reg.1<-merge(pedFile,regPhenos, by.x = "CID",by.y="FID")

## the scales for mph phenos are different- needs to be normalized
## use caret preProcess functions for normalization of each mph phenotype
# preProcess(x, method = c("center", "scale"),
#            thresh = 0.95, pcaComp = NULL, na.remove = TRUE, k = 5,
#            knnSummary = mean, outcome = NULL, fudge = 0.2, numUnique = 3,
#            verbose = FALSE, freqCut = 95/5, uniqueCut = 10, cutoff = 0.9,
#            rangeBounds = c(0, 1), ...)
# predict(object, newdata, ...)
#############

mph.2<-preProcess(mph.1, method = c("center","scale"),na.remove = TRUE)
predict(mph.2,mph.1)->mph.3

# looks alot better when centered and scaled.

reg.2<-preProcess(reg.1, method = c("center","scale"),na.remove = TRUE)
predict(reg.2,reg.1)->reg.3

## there are more correlations between the mph of the traits then there are between traits.
## interesting.
## now need to generate classes for MPH - how to do that?
## after centering and scaling - we can fit the expected normal to the distributions- and
## That would allow for assigning an overall deviation from normal across phenotypes
## expected mean would be 0, and variance is 1- because its centered and scaled
# qqPlot(x, distribution="norm", groups, layout,
# ylim=range(x, na.rm=TRUE), ylab=deparse(substitute(x)),
# xlab=paste(distribution, "quantiles"), glab=deparse(substitute(groups)),
# main=NULL, las=par("las"),
# envelope=.95, col=carPalette()[1], col.lines=carPalette()[2],
# lwd=2, pch=1, cex=par("cex"),
# line=c("quartiles", "robust", "none"), id=TRUE, grid=TRUE, ...)
#############
## there is no way to quantify the amount of deviation without the curvefitting
## Can we do Area under the Curve- to quantify total deviation in a cross?
## or are we only interested in the fraction of data 
## in the high tail and low tail given a cross
## that is the probability of a cross generating- heterotic output, or inferior output.
## given all the crosses.
## how to generalize to the parents then?
## first score the cross as +/-/0 across traits- lets do quartiles
## and pick the outer two quartiles as +/- and inner two quartiles as 0
## did quantiles and deciles
### run the Quantile Conversion Script-**** ###

mph.3d->ds
mph.3q->qs

## now count the number of samples in deciles across phenotypes given a cross
qs$shp<-0
for (i in(1:length(qs[,1]))){
  qs[i,]->a
  b<-sum(length(which(a[5:13]==1)),length(which(a[5:13]==4)))
  qs$shp[i]<-b/9
}

# the shp column now can be utilized as the frequency of
# obtaining a heterotic phenotype given the cross
# high edges will be shorter in length- so maybe do 1- for these values?

# hence the edge-weight between parental nodes
## do the high and the low seperately- 
qs$shp.h<-0
qs$shp.l<-0

for (i in(1:length(qs[,1]))){
  qs[i,]->a
  b<-length(which(a[5:13]==1))
  c<-length(which(a[5:13]==4))
  qs$shp.l[i]<-b/9
  qs$shp.h[i]<-c/9
}
## now use the quartile distribution frequency across traits as edgeLists

edgeList.hh<-qs[,c(2:3,15)]
edgeList.lh<-qs[,c(2:3,16)]
edgeList.xh<-qs[,c(2:3,14)]

## run community link analysis

getLinkCommunities(edgeList.hh,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lch
lch <- newLinkCommsAt(lch, cutat = 3.55)
plot(lch, type = "summary")
plot(lch, type = "dend")
plot(lch, type = "graph", layout = "spencer.circle", pal = customPal, bg = 'grey')
quartz.save("mph-hhF-spencerCircle.png", type = "png", device = dev.cur(), dpi = 300) 


plot(lch, type = "graph", layout = layout.fruchterman.reingold)
plot(lch, type = "graph", layout = layout.kamada.kawai)
plot(lch, type = "graph", shownodesin = 2, node.pies = TRUE)

getLinkCommunities(edgeList.lh,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lcl
lcl <- newLinkCommsAt(lcl, cutat = 3.55)
plot(lcl, type = "summary")
plot(lcl, type = "dend")
plot(lcl, type = "graph", layout = "spencer.circle", pal = customPal, bg = 'grey')
quartz.save("mph-hiF-spencerCircle.png", type = "png", device = dev.cur(), dpi = 300) 


plot(lcl, type = "graph", layout = "spencer.circle")
plot(lch, type = "graph", layout = layout.fruchterman.reingold)
plot(lch, type = "graph", layout = layout.kamada.kawai)
plot(lch, type = "graph", shownodesin = 2, node.pies = TRUE)

## layouts are trivial- will not use these- will recreate in python
## will use stats from the community analysis
## lcx needs a cut off to remove edges
edgeList.xh<-edgeList.xh[which(edgeList.xh[,3]!=0),]

 getLinkCommunities(edgeList.xh,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lcx
 lcx <- newLinkCommsAt(lcx, cutat = 3.9)
 plot(lcx, type = "summary")
 plot(lcx, type = "dend")
 #customPal1<-c(customPal,brewer.pal(4,"Dark2"))
 plot(lcx, type = "graph", layout = "spencer.circle", pal=(customPal))
 quartz.save("mph-hiF+hhF-spencerCircle.png", type = "png", device = dev.cur(), dpi = 300) 

#getCommunityMatrix(lcl)->lcl.cm doesn't have labels for some reason
lcl$nodeclusters->lcl.nc 
dcast(lcl.nc,node~cluster)->lcl.nc.1
## use node's Cluster Membership profile as a class

for( i in (2:6)){
  mt<-lcl.nc.1[,i]
  mt[which(!is.na(mt))]<-1
  mt[which(is.na(mt))]<-0
  lcl.nc.1[,i]<-mt
}

lcl.nc.1$prf<-c("")
for( j in (1:28)){
  cline<-lcl.nc.1[j,2:6]
  cpr<-cline[1]
  for(c in (1:5)){
    cpr<-paste(cpr,cline[c], sep="")
  }
  lcl.nc.1$prf[j]<-cpr
}
## output lcl.nc.1 - has the cluster mebership of the parents for generating
## F1 with phenotype at the low-heterotic tail for 28 parents
## >unique(lcl.nc.1$prf)
## there are 6 different profiles
## ICE119,Qui-0, ICE216, Rue3-1-31,TueWa1-2 have rare phenotypes
## All the rest are the common profile.

## SAME TREATMENT FOR THE HIGH TAIL membership

getCommunityMatrix(lch)->lch.cm
lch$nodeclusters->lch.nc 
dcast(lch.nc,node~cluster)->lch.nc.1
## use node's Cluster Membership profile as a class

for( i in (2:6)){
  mt<-lch.nc.1[,i]
  mt[which(!is.na(mt))]<-1
  mt[which(is.na(mt))]<-0
  lch.nc.1[,i]<-mt
}

lch.nc.1$prf<-c("")
for( j in (1:28)){
  cline<-lch.nc.1[j,2:6]
  cpr<-cline[1]
  for(c in (1:5)){
    cpr<-paste(cpr,cline[c], sep="")
  }
  lch.nc.1$prf[j]<-cpr
}
## output lch.nc.1
## generates 6 profile classes
## Koch-1,Yeg-1 are the most distant - Mer-6,ICE79, ICE29 ,  Fei-0 ,Cdm-0
## rest are the same


## genotype data processing
#read.table("215k_29parentGenos.hmp.txt",skip=1, header=F, sep="\t")->geno.p

read.table("Kmat_parents.txt", skip=3, header=F, sep="\t")->Kp
colnames(Kp)<-c("lines",as.character(Kp$V1))
melt(Kp,id.vars = "lines")->Kpm
## Centered K has negative values - add the min to all values to start at 0
Kpm$value<-Kpm$value+(min(Kpm$value)*-1)
## export out the edgeList try the scaling on python- these layouts are no good.

#write.table(Kpm,"p29_K_edgeList.csv",sep=",", row.names = FALSE)
## Check the correlation between the edgeList for phenotypes and genotypes
## Kpm = Genetic Distance Network

## 10% kinship cut off
Kpm[which(abs(Kpm$value)>0.10),]->kpmr
Kpm[which(abs(Kpm$value)>0.20),]->kpmr
# 
# ###### 10% or more in K cut off
 getLinkCommunities(kpmr,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lck
 lck <- newLinkCommsAt(lck, cutat = 2.45)# for 10% cut off
 lck <- newLinkCommsAt(lck, cutat = 2.25)# for 20% cut off
 lck <- newLinkCommsAt(lck, cutat = 2.03)# for 25% cut off
 
## Create new ColorPallete
 customPal<-c("#FF3300","#33CC33","#C7E9B4","#7FCDBB","#41B6C4","#1D91C0","#225EA8","#FF9933")
 
# plot(lck, type = "summary")
 plot(lck, type = "dend")
 plot(lck, type = "summary")
 plot(lck, type = "graph", layout = "spencer.circle", pal = customPal, bg = 'grey')
 quartz.save("IBS-20p-spencerCircle", type = "png", device = dev.cur(), dpi = 300) 

# plot(lck, type = "graph", layout = layout.fruchterman.reingold)
# plot(lck, type = "graph", layout = layout.kamada.kawai)
# plot(lck, type = "graph", shownodesin = 2, node.pies = TRUE)
## plotLinkCommSumm(lck, col = TRUE, pal = brewer.pal(9, "Set1"), right = TRUE, 
##                  droptrivial = TRUE, verbose = TRUE)


###### no cut off
getLinkCommunities(Kpm,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lck.1
lck.1 <- newLinkCommsAt(lck.1, cutat = 2.6)
plot(lck.1, type = "dend")
plot(lck.1, type = "summary")

plot(lck.1, type = "graph", layout = "spencer.circle")
plot(lck.1, type = "graph", layout = layout.fruchterman.reingold)
plot(lck.1, type = "graph", layout = layout.kamada.kawai)

lck.1.1 <- newLinkCommsAt(lck.1, cutat = 3.8)
plot(lck.1.1, type = "dend")
plot(lck.1.1, type = "summary")

plot(lck.1.1, type = "graph", layout = "spencer.circle")




######*** After doing the genotype- relationship network *****
## Use no cut off

Kpm->gd
edgeList.hh ->hh
edgeList.lh->lh
edgeList.xh->xh

gd$cross<-paste(gd$lines,gd$variable,sep="+")
hh$cross<-paste(hh$P1,hh$P2,sep="+")
lh$cross<-paste(lh$P1,lh$P2,sep="+")
xh$cross<-paste(xh$P1,xh$P2,sep="+")

gdh.1<-merge(gd,hh,by="cross")
gdh.2<-merge(gdh.1,lh, by="cross")
gdh.3<-merge(gdh.2,xh, by ="cross")

gdh.4<-gdh.3[,c(1,4,7,10,13)]
## merge that with phenoMat
## Can evaluate the predictive properties of these nodeProfiles
## by merging them with the phenotypes

merge(pedFile,phenoMat, by.x="CID",by.y ="FID")->ppm
pedFile$cross<-paste(pedFile$P1,pedFile$P2,sep="+")

### *** actual merge below gd- the precursor to the gdh.4 is Kpm
### *** so this analysis uses the G matrix directly- as the value

merge(pedFile,gdh.4, by="cross")->inputReg
merge(inputReg,ppm, by = "CID")->irp
## that is with phenos- now include the mph.q for the quartile classes for transgressiveness

lm(irp[,13]~irp[,6]+irp[,7])->lm1
## this is pretty cool, so 6,7,8 - namely kinship +shp.h+ shp.l 
## explain about ~80+% of the phenotypic variance for almost all traits
## there are exceptions - 
Area_Day_21_.MPH. = 0.7225
LTF_.MPH. = 0.20
Perimeter_Day_21_.MPH. = 0.69
Perimeter_Growth_.MPH. = 0.74
Rosette_Diameter_.MPH. = 0.42
Rosette_Dry_Mass_.MPH. = 0.43

## Exceptions are MPH calculations themselves, which are not actual phenos
## So on real phenos ~80 prediction accuracy with linear model is pretty good.
## phenotype columns 13 thru 29

for ( i in(13:29)){
  lm(irp[,i]~ 0 + irp[,6]+irp[,7]+irp[,8])->lm1
  print(colnames(irp)[i])
  print(summary(lm1))
}
## **** ITS STABLE!!!!

## RUN CROSS VALIDATION FOR MODEL ACCURACY
train_control <- trainControl(method="repeatedcv", number=10, repeats=3, allowParallel = TRUE)
# train the model
# model <- train(Species~., data=iris, trControl=train_control, method="nb")
# summarize results
# print(model)

## I will need training data and training classes
## prMat.2a should have the classes
## create a new file with 6:8 from irp and the pMat.2a
prMat.2a<-prMat.2[,c(1:3,5,18,24,42,48,54,72)]
colnames(prMat.2a)<-c("P2","P1","CID","Area21","lh.p2","hh.p2","gc.p2","lh.p1","hh.p1","gc.p1")

prMat.2q<-merge(prMat.2a,irp, by ="CID")

pm2<-prMat.2q[,c(1:3,5:10,16:18)]

## To do classification I need the quartiles or deciles- or percentiles
## percentiles are pushing it- since there is only 28-29 parents
## start with quartiles
## quantile phenotype files are mph.3q and reg.3q
## merge pm2 with reg.3q
reg.3q->reg.3f
for( i in (5:12)){
  reg.3f[,i]<-as.factor(reg.3f[,i])
}

pm3<-merge(pm2,reg.3f, by="CID")
## now add the irp values 6,7,8
pm4<-merge(pm3,irp[,c(1,6:8)], by="CID")

## deciles
reg.3d->reg.3k
for( i in (5:12)){
  reg.3k[,i]<-as.factor(reg.3k[,i])
}

pm5<-merge(pm2,reg.3k, by="CID")
## now add the irp values 6,7,8
pm6<-merge(pm5,irp[,c(1,6:8)], by="CID")

## try with example
library(caret)
library(MASS)
# data(iris)
# set.seed(1)
# TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
# TrainData    <- iris[-TestRows,1:4]
# TrainClasses <- iris[-TestRows,5]
# TestData     <- iris[TestRows,1:4]
# TestClasses  <- iris[TestRows,5]
# nnetFit <- train(x=TrainData, y=TrainClasses,
#                  method = "nnet",
#                  preProcess = "range", 
#                  tuneLength = 2,
#                  trace = FALSE,
#                  maxit = 100)
# table(TrainClasses, predict(nnetFit)) 
# table(TestClasses,  predict(nnetFit,TestData))
####################
# the phenotype Column needs to be converted to Factor or character
## NA treatment of the phenotype classes
pm4a<-pm4[,c(4:12,24:26,17)]# 16 is the phenotype column
rownames(pm4a)<-pm4$CID
pm4b<-na.exclude(pm4a)

pm6a<-pm6[,c(4:12,24:26,17)]
rownames(pm6a)<-pm6$CID
pm6b<-na.exclude(pm6a)

### Model Fitting Using the quartile assignments of the phenos
### models tested : nnet and rf
### Using all variables

set.seed(42)
TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
TrainData    <- pm4b[-TestRows,c(1:12)]
TrainClasses <- pm4b[-TestRows,13]
TestData     <- pm4b[TestRows,c(1:12)]
TestClasses  <- pm4b[TestRows,13]

nnetFit <- train(x=TrainData, y=TrainClasses,
                 method = "nnet",
                 tuneLength = 3,
                 trace = FALSE,
                 maxit = 100)

table(TrainClasses, predict(nnetFit)) 
table(TestClasses,  predict(nnetFit,TestData))

rfFit <- train(x=TrainData, y=TrainClasses,
                 method = "rf",
                 tuneLength = 3,
                 trace = FALSE,
                 maxit = 100)

# deciles
TrainData    <- pm6b[-TestRows,c(1:12)]
TrainClasses <- pm6b[-TestRows,13]
TestData     <- pm6b[TestRows,c(1:12)]
TestClasses  <- pm6b[TestRows,13]




### Model Fitting Using the quartile assignments of the phenos
### models tested : nnet and rf
### Using only the pairwise genetic similarity, lh and hh


TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
TrainData    <- pm4b[-TestRows,c(10:12)]
TrainClasses <- pm4b[-TestRows,13]
TestData     <- pm4b[TestRows,c(10:12)]
TestClasses  <- pm4b[TestRows,13]

## decent accuracy- but regression models would be better to predict continous phenotypes instead of classes

## parental means have arrived from Danelle
pms<-read.table("2019-05-03_estimated_parental_means.txt", header=T, sep="\t")
hms<-read.table("2019-05-03_estimated_hybrid_means.txt", header=T, sep="\t")
hms$cross<-paste(hms$female,hms$male,sep="+")

## phenotypic distance calculation between the parents
## use pms first
## calculate distance only 28 parents out of 29 genotyped

library(philentropy)
pms.1<-pms[,c(5:14)]
rownames(pms.1)<-pms$cross
as.matrix(distance(pms.1, method="euclidean"))->pms.de # euclidean distance
as.matrix(distance(pms.1, method ="jaccard"))->pms.dj # jacquard distance
rownames(pms.de)<-pms$cross
rownames(pms.dj)<-pms$cross
colnames(pms.de)<-pms$cross
colnames(pms.dj)<-pms$cross


pms.dem<-melt(pms.de)
pms.djm<-melt(pms.dj)

# filter the distance matrix for 20% or more
pms.djm.1<-pms.djm[which(pms.djm$value > 0.025),]
pms.dem.1<-pms.dem[which(pms.dem$value > 20),]

# need edgelist for all pairwise parent combinations

lcp<-getLinkCommunities(pms.djm.1, hcmethod = "ward.D2", 
#                 use.all.edges = FALSE,
#                 edglim = 10^4, directed = FALSE, dirweight = 0.5,
                  bipartite = FALSE, dist = NULL, plot = TRUE,
                  check.duplicates = TRUE, removetrivial = TRUE,
                  verbose = TRUE)

lcp.1 <- newLinkCommsAt(lcp, cutat = 1.84) # 8 clusters
plot(lcp.1, type = "summary")
plot(lcp.1, type = "dend")
plot(lcp.1, type = "graph", layout = "spencer.circle")
plot(lcp.1, type = "graph", layout = "spencer.circle", pal = customPal, bg = 'grey')
quartz.save("PhenoDist-jd.025-spencerCircle", type = "png", device = dev.cur(2), dpi = 300) 

lce<-getLinkCommunities(pms.dem.1, hcmethod = "ward.D2", 
                        #                 use.all.edges = FALSE,
                        #                 edglim = 10^4, directed = FALSE, dirweight = 0.5,
                        bipartite = FALSE, dist = NULL, plot = TRUE,
                        check.duplicates = TRUE, removetrivial = TRUE,
                        verbose = TRUE)

lce.1 <- newLinkCommsAt(lce, cutat = 2.84) # 6 clusters
plot(lce.1, type = "summary")
plot(lce.1, type = "dend")
plot(lce.1, type = "graph", layout = "spencer.circle")
plot(lce.1, type = "graph", layout = "spencer.circle", pal = customPal, bg = 'grey')
quartz.save("PhenoDist-ed20-spencerCircle", type = "png", device = dev.cur(2), dpi = 300) 


## add the parental phenotypes for each phenotype to the mix- and add back the intercept
## create a new input file with the new data from Danelle
dss.1<-irp[,c(2:4,6:8)]
rownames(dss.1)<-irp$CID

#create the trait list with the column headers from the data files

traitList<-colnames(hms)[6:15]
parentList<-as.character(pms$female)

# grab the first trait from both pms and hms and add it to the dss.1
# CID == genotype in hms
# female == male== cross in the pms file  genotype has the PID
# add the female parents' phenotype first, then the male parents' phenotype by CID
# Danelle's files don't have CID but the Cross - get the parents from irp

# This creates a series of objects named <trait_id>.out for each phenotype
for ( i in (1:length(traitList))){
  c.trait<-traitList[i]
  hp1<-hms[,c(1:3,which(colnames(hms)==c.trait))]
  hp1$p1<-0
  hp1$p2<-0
  # for each trait - merge the parental phenotypes to the  progeny phenotype 
  # according to the parent column value in the dss.1
  for( j in (1:length(parentList))){
   c.pid<-parentList[j]
   pp1<-pms[which(pms$female == c.pid),]
   pp1a<-pp1[,which(colnames(pp1)==c.trait)]
   pp1a->hp1$p1[which(hp1$female == c.pid)]

   pp2<-pms[which(pms$male == c.pid),]
   pp2a<-pp1[,which(colnames(pp1)==c.trait)]
   pp2a->hp1$p2[which(hp1$male == c.pid)]
   p.out<-merge(dss.1,hp1,by="cross")
   assign(paste(c.trait,"out",sep="."),p.out)
   # need to store the p.out in its own object
   # the file to be used for prediction the merged dss.1 and hp1 files
   # merge by cross column
  }
}

# fast Methods
methodList1<-c("lm", # linear model
              "kknn", # k- nearest neighbors
              "avNNet", # neural Net Multilayer perceptron
              "elm", #Single Hidden Layer Feedforward Networks - https://rdrr.io/cran/elmNN/man/elmNN-package.html
              "brnn", #Bayesian Regularization for Feed-Forward Neural Networks - https://rdrr.io/cran/brnn/man/brnn.html
              "parRF", # parallel Random Forest
              "cubist", #rulebased model - https://cran.r-project.org/web/packages/Cubist/vignettes/cubist.html - https://rdrr.io/rforge/Cubist/man/cubist.html
              "treebag", #Bootstrap Aggregating Classification-RegressionTrees #https://www.datatechnotes.com/2018/04/classification-with-bagging-treebag.html
              "svmRadialSigma", # Support Vector Regression - Radial Kernel-https://www.kdnuggets.com/2017/03/building-regression-models-support-vector-regression.html
              "svmLinear"
              )

# slow methods need to do 3-4 iterations max
methodList2<-c("evtree", # Tree Models from Genetic Algorithms
               "xgbDART" #eXtreme Gradient Boosting 
)



#ds<-Area_day29_trans.out
for( trt in (1:length(traitList))){
  ds<-eval(as.name(paste(traitList[trt],"out",sep=".")))
  list1 <- list(methodList1[1:8])
  list2 <- as.list(methodList1[1:8])
  
  outList<-list(list1,list2)

  set.seed(42)
  TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
  
  for ( m in (1:length(methodList1))){
    TrainData    <- ds[-TestRows,c(4:6,10:11)]
    TrainClasses <- ds[-TestRows,9]
    TestData     <- ds[TestRows,c(4:6,10:11)]
    TestClasses  <- ds[TestRows,9]
    Fit <- train(x=TrainData, y=TrainClasses,
                 method = methodList1[m],
                 tuneLength = 11,
                 trace = TRUE,
                 maxit = 100)
    outList[[2]][[m]]<-as.list(Fit$results)
    pred.1<-as.data.frame(predict(Fit,TestData))
    rownames(pred.1)->pred.1$CID
    rownames(TestData)->testSampleList
    out.1<-ds[which(rownames(ds) %in% testSampleList),]
    rownames(out.1)->out.1$CID
    merge(out.1,pred.1,by="CID")->xx
    # plot(xx[,10]~xx[,13])
    ## ggplot sctter plot with Error Ribbon
    p1<-ggplot(xx, aes(x=xx[,10], y=xx[,13])) + 
        geom_point()+
        geom_smooth(method=lm, se=TRUE)
    xx$set<-"test"
    colnames(xx)[13]<-"prediction"
    
    
    pred.2<-as.data.frame(predict(Fit,TrainData))
    rownames(pred.2)->pred.2$CID
    rownames(TrainData)->trainSampleList
    out.2<-ds[which(rownames(ds) %in% trainSampleList),]
    rownames(out.2)->out.2$CID
    merge(out.2,pred.2,by="CID")->yy

    p2<-ggplot(yy, aes(x=yy[,10], y=yy[,13])) + 
      geom_point()+
      geom_smooth(method=lm, se=TRUE)
    yy$set <- "train"
    colnames(yy)[13]<-"prediction"
    
    rbind(xx,yy)->zz
    p3<-ggplot(zz, aes(x=zz[,10], y=zz[,13],shape=set,color=set)) + 
      geom_point()+
      geom_smooth(method=lm, se=TRUE,fullrange=FALSE) +
      labs(title= paste(traitList[trt],methodList1[m],"Predicted vs. Observed Cross Values",sep="-"),
         x=traitList[trt], y = "model_predicted_Values")
    ggsave(paste(traitList[trt],methodList1[m],".png",sep=""))
  }## need to change the labels- and add the training data in there too.
  # store the outList in a named list
  assign(paste(traitList[trt],"outlist",sep="."),outList)
}

for( j in (1:length(traitList))){
  tt<-eval(as.name(paste(traitList[j],"outlist",sep=".")))
  print(traitList[j])
  for( i in (1:10)){
    print(max(tt[[2]][[i]]$Rsquared, na.rm = TRUE))
  }
}

## need to see predicted values versus observed- to make sure.


## the result reporting is not good- fix that
## then write an outside loop to do all traits one by one

# test case ltf_trans.out use it for regression and modelling
ds<-Area_day29_trans.out 
# some methods don't work because of missingness
# need to handle the missing data
set.seed(42)
TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
TrainData    <- ds[-TestRows,c(4:6,10:11)]
TrainClasses <- ds[-TestRows,9]
TestData     <- ds[TestRows,c(4:6,10:11)]
TestClasses  <- ds[TestRows,9]

lmFit <- train(x=TrainData, y=TrainClasses,
               method = "lm",
               tuneGrid  = expand.grid(intercept = FALSE),
               tuneLength = 11,
               trace = TRUE,
               maxit = 100)
print(lmFit)
print(lmFit$results)

pred.1<-as.data.frame(predict(lmFit,TestData))
pred.1$CID<-rownames(pred.1)
rownames(TestData)->testSampleList
out.1<-ds[which(rownames(ds) %in% testSampleList),]
out.1$CID<-rownames(out.1)
merge(out.1,pred.1,by="CID")->xx
plot(xx[,5]~xx[,6])


lmFit1 <- train(x=TrainData, y=TrainClasses,
                 method = "lm",
                 tuneLength = 11,
                 trace = FALSE,
                 maxit = 100)

nnetFit <- train(x=TrainData, y=TrainClasses,
                 method = "avNNet",#nnet
                 tuneLength = 11,
                 trace = FALSE,
                 maxit = 100)

rfFit1 <- train(x=TrainData, y=TrainClasses,
               method = "rf",
               tuneLength = 11,
               trace = FALSE,
               maxit = 100)

rfFit <- train(x=TrainData, y=TrainClasses,
               method = "parRF",
               tuneLength = 11,
               trace = FALSE,
               maxit = 100)

knnFit <- train(x=TrainData, y=TrainClasses,
               method = "kknn",
               tuneLength = 11,
               trace = FALSE,
               maxit = 100)

bstFit <- train(x=TrainData, y=TrainClasses,
               method = "xgbDART",
               tuneLength = 2,
               trace = FALSE,
               maxit = 100)

cubistFit <- train(x=TrainData, y=TrainClasses,
                method = "cubist",
                tuneLength = 3,
                trace = FALSE,
                maxit = 100)

elmFit <- train(x=TrainData, y=TrainClasses,
                   method = "elm",
                   tuneLength = 3,
                   trace = FALSE,
                   maxit = 100)

brnnFit <- train(x=TrainData, y=TrainClasses,
                method = "brnn",
                tuneLength = 11,
                trace = FALSE,
                maxit = 100)

baggedCARTFit <- train(x=TrainData, y=TrainClasses,
                 method = "treebag",
                 tuneLength = 11,
                 trace = FALSE,
                 maxit = 100)

baggedMARSFit <- train(x=TrainData, y=TrainClasses,
                       method = "bagEarth",
                       tuneLength = 11,
                       trace = FALSE,
                       maxit = 100)

svmFit<-train(x=TrainData, y=TrainClasses,
              method = "svmRadial",
              tuneLength = 11,
              trace = FALSE,
              maxit = 100)

svmFit1<-train(x=TrainData, y=TrainClasses,
              method = "svmLinear",
              tuneLength = 11,
              trace = FALSE,
              maxit = 100)

svmFit2<-train(x=TrainData, y=TrainClasses,
              method = "svmRadialSigma",
              tuneLength = 11,
              trace = FALSE,
              maxit = 100)

genFit<-train(x=TrainData, y=TrainClasses,
              method = "evtree",
              tuneLength = 11,
              trace = FALSE,
              maxit = 100)

## For regression use irp
## this is testing for lm regression
irp.s<-irp[,c(6:8,13:29)]
rownames(irp.s)<-irp$CID

for( i in(4:20)){
ds<-irp.s[,c(1:3,i)]
set.seed(42) # results are not stable without seed.
TestRows     <- c(sample(50,15), sample(50,15)+50, sample(50,15)+100)
TrainData    <- ds[-TestRows,c(1:3)]
TrainClasses <- ds[-TestRows,4]
TestData     <- ds[TestRows,c(1:3)]
TestClasses  <- pm4b[TestRows,4]
lmFit <- train(x=TrainData, y=TrainClasses,
                 method = "lm",
#               tuneGrid  = expand.grid(intercept = FALSE),
                 tuneLength = 11,
                 trace = TRUE,
                 maxit = 100)
print(colnames(irp.s)[i])
print(summary(lmFit))
pred.1<-as.data.frame(predict(lmFit,TestData))
pred.1$CID<-rownames(pred.1)
rownames(TestData)->testSampleList
out.1<-ds[which(rownames(ds) %in% testSampleList),]
out.1$CID<-rownames(out.1)
merge(out.1,pred.1,by="CID")->xx
plot(xx[,5]~xx[,6])
}


#for ( i in(13:29)){
for ( i in(13:14)){
  indata<-irp[,c(i,6:8)]
  rownames(indata)<-irp$CID
#  lm(irp[,i]~ 0 + irp[,6]+irp[,7]+irp[,8])->lm1
  model<-train(indata[,1]~., data=indata,trControl=train_control,
               method = 'glm')
#                method = 'gpls')
               #method = 'BstLm', mstop= 1000, nu=0.5)#method = 'bayesglm')# method="nb")
  print(colnames(irp)[i])
#  print(summary(lm1))
  print(model)
}



for ( i in(13:29)){
  lm(irp[,i]~ 0 + irp[,6]+irp[,7]+irp[,8])->lm1
  print(colnames(irp)[i])
  print(summary(lm1))

  lm(irp[,i]~ 0 + irp[,7]+irp[,8]+irp[,6])->lm2
  print(colnames(irp)[i])
  print(summary(lm2))
  
}
## output irp
write.table(irp,"regressionInputFile.csv",sep=",",row.names = FALSE)
## Need to try cross validation with 6,7,8 prediction of the phenotypes

## so now that we know 6-7-8 are significant- lets see what graph topology
## does to improve the percent variance explained.
## Output the graph parameters for each

irp.1<-irp[,c(1:4,6:8)]
# networks = [,6]=lck.1 ; [,7]=lch ; [,8]=lcl
objList<-c("lck.1","lch","lcl")
# first I need to get community assignments

getCommunityMatrix(lck.1)->lck.cm
lck.1$nodeclusters->lck.nc 
dcast(lck.nc,node~cluster)->lck.nc.1
## use node's Cluster Membership profile as a class

for( i in (2:9)){
 mt<-lck.nc.1[,i]
 mt[which(!is.na(mt))]<-1
 mt[which(is.na(mt))]<-0
 lck.nc.1[,i]<-mt
}

lck.nc.1$prf<-c("")
for( j in (1:29)){
  cline<-lck.nc.1[j,2:9]
  cpr<-cline[1]
  for(c in (2:8)){
  cpr<-paste(cpr,cline[c], sep="")
  }
  lck.nc.1$prf[j]<-cpr
}

#lck.nc.1$prf contains the cluster membership profile based on genetic distance
# lines with the same prf are in the same category
# 11 categories across 29 parents

unique(lck.nc.1[,19])->catList

for( i in (1:length(catList))){
c.class<-droplevels(lck.nc.1[which(lck.nc.1$prf == as.character(catList[i])),])
print(c.class$node)
}
# Levels G1 : Cdm-0 ICE107 ICE119 ICE181 ICE228 ICE92 Mer-6
# Levels G2 : Fei-0 TueWa1-2
# Levels G3 : Qui-0
# Levels G4 : ICE150 ICE61 ICE72 ICE73 Sha Yeg-1
# Levels G5 : Ey15-2
# Levels G6 : HKT2.4
# Levels G7 : ICE212 ICE79 Rue3-1-31
# Levels G8 : Nie1-2
# Levels G9 : ICE111
# Levels G10: Koch-1
# Levels G11: Bak-2 ICE216 ICE29 ICE50 ICE63

## I am attempting to use the genetic relationship profile instead of actual value here
# cluster assignment per entry individuals can have assignmets to multiple clusters

## merge lck.nc.1,lcl.nc.1, lch.nc.1
p.mat<-merge(lcl.nc.1,lch.nc.1, by = "node")
pmat<-merge(p.mat,lck.nc.1, by ="node")

## merge with phenotypes based on parents
## mph.1 midparent heterosis values
## reg.1 regular phenotypes of the F1s
merge(reg.1,pmat, by.x = "P1", by.y = "node", all.x = TRUE)->prMat.1
merge(prMat.1,pmat, by.x = "P2", by.y = "node", all.x = TRUE)->prMat.2

## can clean up this matrix somewhat
prMat.2a<-prMat.2[,c(1:3,5,18,24,42,48,54,72)]
colnames(prMat.2a)<-c("P2","P1","CID","Area21","lh.p2","hh.p2","gc.p2","lh.p1","hh.p1","gc.p1")

## This is parent class by parent class interaction model
## Loop this for all phenos
pheList<-colnames(prMat.2)
for ( i in (5:12)){# phenotype colums start and end
  prMat.2a<-prMat.2[,c(1:3,i,18,24,42,48,54,72)]
  colnames(prMat.2a)<-c("P2","P1","CID",pheList[i],"lh.p2","hh.p2","gc.p2","lh.p1","hh.p1","gc.p1")
  lf1<-lm(prMat.2a[,4]~  prMat.2a[,5]:prMat.2[,10] + prMat.2a[,6]:prMat.2a[,8] + prMat.2a[,7]:prMat.2a[,9] )
  print(pheList[i])
  print(anova(lf1))
  print(summary(lf1)$r.squared)
  print(summary(lf1)$adj.r.squared)
}

# use RF to predict the accuracy of predicting phenotype quartiles
## reg.q is the quartile file reg.d is the decile file
prMat.3<-merge(prMat.2,reg.3q, by="CID")
prMat.4<-merge(prMat.3,mph.3q, by="CID")


## Output options
# lck.1$clusters #list of indexids per cluster members
# lck.1$numclusters #number of clusters each indv belongs to
# lck.1$clustsizes # cluster sizes
# lck.1$igraph #igraph object for plotting the network
# getClusterRelatedness(lck.1) # creates a dendrogram
# getCommunityConnectedness(lck.1)
# getCommunityCentrality(lck.1) # correlated with numclusters
# getCommunityConnectedness(lck.1) # measure of connectedness
# getCommunityMatrix(lck.1) # nodes vs community membership
# LinkDensities(lck.1)
# get.shared.nodes
##############################


########****maize****##################
setwd("//Users/Shared/Files From d.localized/Elhan/Trifecta/DL282g2x-validation/tasselFiles/")
inbred.K<- read.table("pheno_input_tsl.csv", sep=",", header=T)
fileList<-list.files(pattern="fg_c")
fileList<-fileList[c(2:10,1)]

for ( i in c(1:10)){
  read.table(fileList[i], header=F, sep="\t", skip=2)->a
  colnames(a)<-c("lines",as.character(a$V1))
  melt(a)->b
  c<-droplevels(b[which(b$value >0.5),])
  getLinkCommunities(c,hcmethod="ward.D2", directed=TRUE, bipartite = FALSE)->lc1
  nc<-as.data.frame(lc1$nodeclusters)
  colnames(nc)<-c("line",paste("cluster_c",i,sep="."))
  assign(paste("GDI_c",i,sep=""),c)
  assign(paste("GDC_c",i,sep=""),lc1)
  assign(paste("GNC_c",i,sep=""),nc)
}

#merge all GNCs into a table
cc1<-GNC_c1
cc1$cluster_c.1<-as.numeric(as.character(cc1$cluster_c.1))
for(i in (2:10)){
  cx<-eval(as.name(paste("GNC_c",i,sep="")))
  cx[,2]<-as.numeric(as.character(cx[,2]))
  merge(cc1,cx, by="line")->cc1
}
setwd("~/Desktop/Archive_April2019/CSJ-Review/Revisions/")
## what else can be done with cc1 ? use each chrom as a feature?

read.table("edgeList_FBRC.csv", header=T, sep=",")->fb1
edgeList<-fb1

getLinkCommunities(edgeList, directed=FALSE, bipartite = FALSE)->lcm.1
getLinkCommunities(edgeList,hcmethod="ward.D2", directed=FALSE, bipartite = FALSE)->lcm
plot(lcm.1, type = "graph", layout = "spencer.circle")
plot(lcm.1, type = "graph", layout = "fructerman-reingold")

#lc1.1 <- newLinkCommsAt(lc1, cutat = 1.3)

#write.table(cc1,"Haplotypes.csv",sep=",")
# calculate pairwise distance based on chrom haplotype groups.
#calculate similarity matrix for cluster membership across all chromosomes.
dist(as.matrix(cc1), method = "euclidean", diag = FALSE, upper = FALSE, p = 2)->d1
as.matrix(d1)->md1
colnames(md1)<-cc1[,1]
rownames(md1)<-cc1[,1]
melt(md1)->md1.long
md1.long.1<-md1.long[order(md1.long$value),]
md1.long.2a<-unique(md1.long.1)

# remove 0 s and duplicates

md1.long.2<-md1.long.1[which(md1.long.1$value>0),]

# create variables that is Var1+Var2 and Var2+Var1
md1.long.2$V12<-paste(md1.long.2$Var1,md1.long.2$Var2,sep="")
md1.long.2$V21<-paste(md1.long.2$Var2,md1.long.2$Var1,sep="")
md1.long.3<-unique(md1.long.2)

md1.long.3$Var1<-as.character(md1.long.3$Var1)
md1.long.3$Var2<-as.character(md1.long.3$Var2)

mdf1<-as.data.frame(md1.long.3)
mdf1<-mdf1[,-c(4:5)]

dcast(mdf1,Var1~Var2,mean,value.var = "value")->mdf1c
eigen(md1)->edf1

#create a network out of mdf1
edgeList<-mdf1

getLinkCommunities(edgeList, directed=TRUE, bipartite = FALSE)->lcm.1
getLinkCommunities(edgeList,hcmethod="ward.D2", directed=TRUE, bipartite = FALSE)->lcm
#lc1.1 <- newLinkCommsAt(lc1, cutat = 1.3)
plot(lcm, type = "graph", layout = "fruchterman.reingold")
plot(lcm, type = "graph")
# # create unique identifiers for the remaing set of 513517 entries left.
# md1.long.4<-data.frame(
#   Var1 = character(0L),
#   Var2 = character(0L),
#   value = integer(0),
#   V12 = character(0L),
#   V21 = character(0L),
#   index = integer(0),
#   LID = character(0L)
# )
# 
# uqLines<-unique(md1.long.3$Var1)
# for( i in (1:length(uqLines))){
#   n1<-as.character(uqLines[i])
#   if((md1.long.3$Var1==md1.long.3$Var2) && (n1==md1.long.3$Var1)){
#     list.n1<-md1.long.3[which(md1.long.3$Var1 == n1),]
#     list.n1$index<-seq(1:length(list.n1$Var1))
#     list.n1$LID<-paste(list.n1$Var1,list.n1$index,sep=".")
#     rbind(md1.long.4,list.n1)->md1.long.4
#   }
# }
hclust(t(cc1[,2:10]))->hc1

cor(as.matrix(t(cc1[,2:10])))->cx1
colnames(cx1)<-cc1[,1]
rownames(cx1)<-cc1[,1]
melt(cx1)->mcx1
mcx2<-mcx1[which(mcx1$value > 0.5),]
getLinkCommunities(mcx2,hcmethod="ward.D2", directed=TRUE, bipartite = FALSE)->lc2
plot(lc2, type = "graph", layout = "spencer.circle")
plot(lc2, type = "graph", layout = "fruchterman.reingold")

dist(cc1[,2:10], method = "euclidean", diag = FALSE, upper = FALSE, p = 2)->d1
hclust(d1)->hc1

write.table(cc1,"DL282_community.txt",sep="\t",row.names = FALSE)


## variable number of communities for each chromosome.
## will need a graph for each chromosome- and it will be connected community graphs
# Line 1 - c1-comm, c2-comm, c3-comm,.. etc will need to be collected.
## how do we output the community membership info?

# linearize the K matrix
edgeList<-c

getLinkCommunities(edgeList,hcmethod="ward.D2", directed=TRUE, bipartite = FALSE)->lc1
lc1.1 <- newLinkCommsAt(lc1, cutat = 1.3)





shs_b73xch111.K.txt